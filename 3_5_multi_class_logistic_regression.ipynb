{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "M = 2\n",
    "K = 3\n",
    "n = 100\n",
    "N = n * K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X1 = np.random.randn(n, M) + np.array([0, 10])\n",
    "X2 = np.random.randn(n, M) + np.array([5, 5])\n",
    "X3 = np.random.randn(n, M) + np.array([10, 0])\n",
    "Y1 = np.array([[1, 0, 0] for i in range(n)])\n",
    "Y2 = np.array([[0, 1, 0] for i in range(n)])\n",
    "Y3 = np.array([[0, 0, 1] for i in range(n)])\n",
    "\n",
    "X = np.concatenate((X1, X2, X3), axis=0)\n",
    "Y = np.concatenate((Y1, Y2, Y3), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.zeros([M, K]))\n",
    "b = tf.Variable(tf.zeros([K]))\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, M])\n",
    "t = tf.placeholder(tf.float32, shape=[None, K])\n",
    "y = tf.nn.softmax(tf.matmul(x, W) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(t * tf.log(y), reduction_indices=[1])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_step = tf.train.GradientDescentOptimizer(0.1).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(t, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "n_batches = N // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "for epoch in range(20):\n",
    "    X_, Y_ = shuffle(X, Y)\n",
    "    \n",
    "    for i in range(n_batches):\n",
    "        start = i * batch_size\n",
    "        end = start + batch_size\n",
    "        \n",
    "        sess.run(train_step, feed_dict={\n",
    "            x:X_[start:end],\n",
    "            t:Y_[start:end]\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classified: \n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      "\n",
      "output probability: \n",
      " [[  5.64577756e-03   9.88054812e-01   6.29938953e-03]\n",
      " [  1.44765392e-01   8.54136705e-01   1.09797483e-03]\n",
      " [  9.86593068e-01   1.34069324e-02   5.86681459e-09]\n",
      " [  9.58921191e-08   5.92853129e-02   9.40714598e-01]\n",
      " [  9.95771945e-01   4.22804477e-03   6.24577812e-09]\n",
      " [  9.97860610e-01   2.13935087e-03   1.69078707e-08]\n",
      " [  1.87107130e-09   4.55825496e-03   9.95441675e-01]\n",
      " [  2.02955622e-02   9.59287643e-01   2.04168297e-02]\n",
      " [  2.52857688e-03   8.14478874e-01   1.82992563e-01]\n",
      " [  1.48566288e-08   1.33185545e-02   9.86681461e-01]]\n"
     ]
    }
   ],
   "source": [
    "X_, Y_ = shuffle(X, Y)\n",
    "\n",
    "classified = correct_prediction.eval(session=sess, feed_dict={x: X_[0:10], t: Y_[0:10]})\n",
    "prob = y.eval(session=sess, feed_dict={x: X_[0:10]})\n",
    "print('classified: \\n', classified)\n",
    "print()\n",
    "print('output probability: \\n', prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(input_dim=M, units=K))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=SGD(lr=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "300/300 [==============================] - 0s 178us/step - loss: 3.0767\n",
      "Epoch 2/20\n",
      "300/300 [==============================] - 0s 32us/step - loss: 0.2709\n",
      "Epoch 3/20\n",
      "300/300 [==============================] - 0s 21us/step - loss: 0.1659\n",
      "Epoch 4/20\n",
      "300/300 [==============================] - 0s 22us/step - loss: 0.1263\n",
      "Epoch 5/20\n",
      "300/300 [==============================] - 0s 20us/step - loss: 0.1034\n",
      "Epoch 6/20\n",
      "300/300 [==============================] - 0s 33us/step - loss: 0.0878\n",
      "Epoch 7/20\n",
      "300/300 [==============================] - 0s 20us/step - loss: 0.0772\n",
      "Epoch 8/20\n",
      "300/300 [==============================] - 0s 18us/step - loss: 0.0693\n",
      "Epoch 9/20\n",
      "300/300 [==============================] - 0s 20us/step - loss: 0.0633\n",
      "Epoch 10/20\n",
      "300/300 [==============================] - 0s 18us/step - loss: 0.0577\n",
      "Epoch 11/20\n",
      "300/300 [==============================] - 0s 20us/step - loss: 0.0530\n",
      "Epoch 12/20\n",
      "300/300 [==============================] - 0s 18us/step - loss: 0.0494\n",
      "Epoch 13/20\n",
      "300/300 [==============================] - 0s 20us/step - loss: 0.0463\n",
      "Epoch 14/20\n",
      "300/300 [==============================] - 0s 18us/step - loss: 0.0441\n",
      "Epoch 15/20\n",
      "300/300 [==============================] - 0s 21us/step - loss: 0.0419\n",
      "Epoch 16/20\n",
      "300/300 [==============================] - 0s 18us/step - loss: 0.0395\n",
      "Epoch 17/20\n",
      "300/300 [==============================] - 0s 22us/step - loss: 0.0375\n",
      "Epoch 18/20\n",
      "300/300 [==============================] - 0s 18us/step - loss: 0.0362\n",
      "Epoch 19/20\n",
      "300/300 [==============================] - 0s 19us/step - loss: 0.0344\n",
      "Epoch 20/20\n",
      "300/300 [==============================] - 0s 21us/step - loss: 0.0332\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f93aee76d30>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minibatch_size=50\n",
    "model.fit(X, Y, epochs=20, batch_size=minibatch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 623us/step\n",
      "10/10 [==============================] - 0s 447us/step\n",
      "classified: \n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      "\n",
      "output probability: \n",
      " [[  9.08883351e-08   1.06551550e-01   8.93448353e-01]\n",
      " [  6.56254683e-03   9.49420452e-01   4.40170243e-02]\n",
      " [  1.18937997e-08   2.86523253e-02   9.71347690e-01]\n",
      " [  9.80829835e-01   1.91701204e-02   1.57659894e-08]\n",
      " [  9.49359715e-01   5.06401211e-02   1.57890597e-07]\n",
      " [  1.58135137e-07   6.64269999e-02   9.33572888e-01]\n",
      " [  8.85825013e-09   7.54037593e-03   9.92459595e-01]\n",
      " [  8.52790549e-09   2.50489730e-02   9.74950969e-01]\n",
      " [  7.68515542e-02   9.20742512e-01   2.40591890e-03]\n",
      " [  9.20356035e-01   7.96428025e-02   1.17799198e-06]]\n"
     ]
    }
   ],
   "source": [
    "X_, Y_ = shuffle(X, Y)\n",
    "classes = model.predict_classes(X_[0:10], batch_size=minibatch_size)\n",
    "prob=model.predict_proba(X_[0:10], batch_size=1)\n",
    "print('classified: \\n', np.argmax(model.predict(X_[0:10]), axis=1) == classes)\n",
    "print()\n",
    "print('output probability: \\n', prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
