{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shimazu/.pyenv/versions/anaconda3-5.0.1/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "M = 2\n",
    "K = 3\n",
    "n = 100\n",
    "N = n * K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X1 = np.random.randn(n, M) + np.array([0, 10])\n",
    "X2 = np.random.randn(n, M) + np.array([5, 5])\n",
    "X3 = np.random.randn(n, M) + np.array([10, 0])\n",
    "Y1 = np.array([[1, 0, 0] for i in range(n)])\n",
    "Y2 = np.array([[0, 1, 0] for i in range(n)])\n",
    "Y3 = np.array([[0, 0, 1] for i in range(n)])\n",
    "\n",
    "X = np.concatenate((X1, X2, X3), axis=0)\n",
    "Y = np.concatenate((Y1, Y2, Y3), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.zeros([M, K]))\n",
    "b = tf.Variable(tf.zeros([K]))\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, M])\n",
    "t = tf.placeholder(tf.float32, shape=[None, K])\n",
    "y = tf.nn.softmax(tf.matmul(x, W) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(t * tf.log(y), reduction_indices=[1])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_step = tf.train.GradientDescentOptimizer(0.1).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(t, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "n_batches = N // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "for epoch in range(20):\n",
    "    X_, Y_ = shuffle(X, Y)\n",
    "    \n",
    "    for i in range(n_batches):\n",
    "        start = i * batch_size\n",
    "        end = start + batch_size\n",
    "        \n",
    "        sess.run(train_step, feed_dict={\n",
    "            x:X_[start:end],\n",
    "            t:Y_[start:end]\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classified: \n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      "\n",
      "output probability: \n",
      " [[  3.53779089e-10   2.22938973e-03   9.97770667e-01]\n",
      " [  7.46819451e-02   9.20228422e-01   5.08960616e-03]\n",
      " [  2.34573451e-03   9.25179183e-01   7.24750534e-02]\n",
      " [  7.57955573e-11   4.22595302e-04   9.99577463e-01]\n",
      " [  5.03602251e-03   9.77156460e-01   1.78074967e-02]\n",
      " [  9.98733819e-01   1.26621465e-03   3.05645093e-10]\n",
      " [  6.24510236e-02   9.28155363e-01   9.39360354e-03]\n",
      " [  1.53760901e-02   9.11862433e-01   7.27615505e-02]\n",
      " [  2.32657269e-02   9.44902062e-01   3.18322815e-02]\n",
      " [  1.31470085e-10   4.37288109e-04   9.99562681e-01]]\n"
     ]
    }
   ],
   "source": [
    "X_, Y_ = shuffle(X, Y)\n",
    "\n",
    "classified = correct_prediction.eval(session=sess, feed_dict={x: X_[0:10], t: Y_[0:10]})\n",
    "prob = y.eval(session=sess, feed_dict={x: X_[0:10]})\n",
    "print('classified: \\n', classified)\n",
    "print()\n",
    "print('output probability: \\n', prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(input_dim=M, units=K))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=SGD(lr=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "300/300 [==============================] - 0s 172us/step - loss: 2.1562\n",
      "Epoch 2/20\n",
      "300/300 [==============================] - 0s 33us/step - loss: 0.1822\n",
      "Epoch 3/20\n",
      "300/300 [==============================] - 0s 24us/step - loss: 0.1309\n",
      "Epoch 4/20\n",
      "300/300 [==============================] - 0s 29us/step - loss: 0.1084\n",
      "Epoch 5/20\n",
      "300/300 [==============================] - 0s 21us/step - loss: 0.0902\n",
      "Epoch 6/20\n",
      "300/300 [==============================] - 0s 18us/step - loss: 0.0786\n",
      "Epoch 7/20\n",
      "300/300 [==============================] - 0s 17us/step - loss: 0.0700\n",
      "Epoch 8/20\n",
      "300/300 [==============================] - 0s 18us/step - loss: 0.0639\n",
      "Epoch 9/20\n",
      "300/300 [==============================] - 0s 20us/step - loss: 0.0582\n",
      "Epoch 10/20\n",
      "300/300 [==============================] - 0s 23us/step - loss: 0.0541\n",
      "Epoch 11/20\n",
      "300/300 [==============================] - 0s 22us/step - loss: 0.0506\n",
      "Epoch 12/20\n",
      "300/300 [==============================] - 0s 24us/step - loss: 0.0477\n",
      "Epoch 13/20\n",
      "300/300 [==============================] - 0s 16us/step - loss: 0.0443\n",
      "Epoch 14/20\n",
      "300/300 [==============================] - 0s 18us/step - loss: 0.0420\n",
      "Epoch 15/20\n",
      "300/300 [==============================] - 0s 19us/step - loss: 0.0399\n",
      "Epoch 16/20\n",
      "300/300 [==============================] - 0s 16us/step - loss: 0.0381\n",
      "Epoch 17/20\n",
      "300/300 [==============================] - 0s 15us/step - loss: 0.0364\n",
      "Epoch 18/20\n",
      "300/300 [==============================] - 0s 19us/step - loss: 0.0350\n",
      "Epoch 19/20\n",
      "300/300 [==============================] - 0s 15us/step - loss: 0.0337\n",
      "Epoch 20/20\n",
      "300/300 [==============================] - 0s 15us/step - loss: 0.0324\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efcf4478a90>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minibatch_size=50\n",
    "model.fit(X, Y, epochs=20, batch_size=minibatch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 745us/step\n",
      "10/10 [==============================] - 0s 791us/step\n",
      "classified: \n",
      " [ True  True  True  True  True  True  True  True  True  True]\n",
      "\n",
      "output probability: \n",
      " [[  9.58095193e-01   4.19004373e-02   4.38166035e-06]\n",
      " [  9.92684960e-01   7.31501821e-03   1.19502657e-08]\n",
      " [  3.73565445e-09   2.76344810e-02   9.72365499e-01]\n",
      " [  2.63884244e-03   9.58413064e-01   3.89480405e-02]\n",
      " [  9.82392907e-01   1.76069941e-02   6.43718892e-08]\n",
      " [  9.12567437e-01   8.74322504e-02   3.49182983e-07]\n",
      " [  2.18676882e-10   3.08748079e-03   9.96912479e-01]\n",
      " [  3.91869247e-02   9.50916529e-01   9.89645254e-03]\n",
      " [  1.98372561e-07   2.31321957e-02   9.76867557e-01]\n",
      " [  4.11550514e-03   9.75039363e-01   2.08450779e-02]]\n"
     ]
    }
   ],
   "source": [
    "X_, Y_ = shuffle(X, Y)\n",
    "classes = model.predict_classes(X_[0:10], batch_size=minibatch_size)\n",
    "prob=model.predict_proba(X_[0:10], batch_size=1)\n",
    "print('classified: \\n', np.argmax(model.predict(X_[0:10]), axis=1) == classes)\n",
    "print()\n",
    "print('output probability: \\n', prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
