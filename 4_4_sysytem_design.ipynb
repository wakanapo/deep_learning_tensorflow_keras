{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "mnist = datasets.fetch_mldata('MNIST original', data_home='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shimazu/.pyenv/versions/anaconda3-5.0.1/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "N_train = 20000\n",
    "N_validation = 4000\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(mnist.data, mnist.target, train_size=N_train)\n",
    "X_train, X_validation, Y_train, Y_calidation = train_test_split(X_train, Y_train, test_size=N_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN(object):\n",
    "    def __init__(self, n_in, n_hiddens, n_out):    \n",
    "        self.n_in = n_in\n",
    "        self.n_hiddens = n_hiddens\n",
    "        self.n_out = n_out\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        self._x = None\n",
    "        self._t = None\n",
    "        self._keep_prob = None\n",
    "        self._sess = None\n",
    "        self._history = {\n",
    "            'accuracy': [],\n",
    "            'loss': []\n",
    "        }\n",
    "\n",
    "    def weight_variable(self, shape):\n",
    "        initial = tf.truncated_normal(shape, stddev=0.01)\n",
    "        return tf.Variable(initial)\n",
    "\n",
    "    def bias_variable(self, shape):\n",
    "        initial = tf.zeros(shape)\n",
    "        return tf.Variable(initial)\n",
    "\n",
    "    def inference(self, x, keep_prob):\n",
    "        # 入力層 - 隠れ層, 隠れ層 - 隠れ層\n",
    "        for i, n_hidden in enumerate(self.n_hiddens):\n",
    "            if i == 0:\n",
    "                input = x\n",
    "                input_dim = self.n_in\n",
    "            else:\n",
    "                input = output\n",
    "                input_dim = self.n_hiddens[i-1]\n",
    "\n",
    "            self.weights.append(self.weight_variable([input_dim, n_hidden]))\n",
    "            self.biases.append(self.bias_variable([n_hidden]))\n",
    "\n",
    "            h = tf.nn.relu(tf.matmul(input, self.weights[-1]) + self.biases[-1])\n",
    "            output = tf.nn.dropout(h, keep_prob)\n",
    "\n",
    "        # 隠れ層 - 出力層\n",
    "        self.weights.append(self.weight_variable([self.n_hiddens[-1], self.n_out]))\n",
    "        self.biases.append(self.bias_variable([self.n_out]))\n",
    "        y = tf.nn.softmax(tf.matmul(output, self.weights[-1]) + self.biases[-1])\n",
    "        return y\n",
    "\n",
    "    def loss(self, y, t):\n",
    "        cross_entropy = tf.reduce_mean(\n",
    "        -tf.reduce_sum(t * tf.log(y), reduction_indices=[1]))\n",
    "        return cross_entropy\n",
    "\n",
    "    def training(self, loss):\n",
    "        optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "        train_step = optimizer.minimize(loss)\n",
    "        return train_step\n",
    "    \n",
    "    def accuracy(self, y, t):\n",
    "        correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(t, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        return accuracy\n",
    "\n",
    "    def fit(self, X_train, Y_train,\n",
    "           epochs=100, batch_size=100, p_keep=0.5, verbose=1):\n",
    "        x = tf.placeholder(tf.float32, shape=[None, self.n_in])\n",
    "        t = tf.placeholder(tf.float32, shape=[None, self.n_out])\n",
    "        keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "        # evaluate()用に保持\n",
    "        self._x = x\n",
    "        self._t = t\n",
    "        self._keep_prob = keep_prob\n",
    "\n",
    "        y = self.inference(x, keep_prob)\n",
    "        loss = self.loss(y, t)\n",
    "        train_step = self.training(loss)\n",
    "        accuracy = self.accuracy(y, t)\n",
    "\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess = tf.Session()\n",
    "        sess.run(init)\n",
    "\n",
    "        # evaluate()用に保持\n",
    "        self._sess = sess\n",
    "\n",
    "        N_train = len(X_train)\n",
    "        n_batches = N_train // batch_size\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            X_, Y_ = shuffle(X_train, Y_train)\n",
    "\n",
    "            for i in range(n_batches):\n",
    "                start = i * batch_size\n",
    "                end = start + batch_size\n",
    "\n",
    "                sess.run(train_step, feed_dict={\n",
    "                    x: X_[start:end],\n",
    "                    t: Y_[start:end],\n",
    "                    keep_prob: p_keep\n",
    "                })\n",
    "            loss_ = loss.eval(session=sesss, feed_dixt={\n",
    "                x: X_train,\n",
    "                t: Y_train,\n",
    "                keep_prob: 1.0\n",
    "            })    \n",
    "            accuracy_ = accuracy.eval(session=sesss, feed_dixt={\n",
    "                x: X_train,\n",
    "                t: Y_train,\n",
    "                keep_prob: 1.0\n",
    "            })\n",
    "            # 値を記録しておく\n",
    "            self._history['loss'].append(loss_)\n",
    "            self._history['accuracy'].append(accuracy_)\n",
    "\n",
    "            if verbose:\n",
    "                print('epoch: ', epoch,\n",
    "                     ' loss: ', loss_,\n",
    "                     ' accuracy: ', accuracy_)\n",
    "            return self._history\n",
    "\n",
    "    def evaluate(self, X_test, Y_test):\n",
    "        return self.accuracy.eval(session=self._sess, feed_dict={\n",
    "            self._x: X_test,\n",
    "            self._t: Y_test,\n",
    "            self._keep_prob: 1.0\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (200,) for Tensor 'Placeholder_41:0', which has shape '(?, 10)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-ad2f32731274>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m            \u001b[0mn_hiddens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m            n_out=10)\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_keep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'accuracy: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-52-106a2b12da12>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X_train, Y_train, epochs, batch_size, p_keep, verbose)\u001b[0m\n\u001b[1;32m     96\u001b[0m                     \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mY_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m                     \u001b[0mkeep_prob\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mp_keep\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m                 })\n\u001b[1;32m    100\u001b[0m             loss_ = loss.eval(session=sesss, feed_dixt={\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.0.1/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.0.1/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1094\u001b[0m                 \u001b[0;34m'Cannot feed value of shape %r for Tensor %r, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m                 \u001b[0;34m'which has shape %r'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1096\u001b[0;31m                 % (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m   1097\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor %s may not be fed.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (200,) for Tensor 'Placeholder_41:0', which has shape '(?, 10)'"
     ]
    }
   ],
   "source": [
    "model = DNN(n_in=784,\n",
    "           n_hiddens=[200, 200, 200],\n",
    "           n_out=10)\n",
    "model.fit(X_train, Y_train, epochs=50, batch_size=200, p_keep=0.5)\n",
    "accuracy - model.evaluate(X_test, Y_test)\n",
    "print('accuracy: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_in = len(X[0])  # 784\n",
    "n_hidden = 200\n",
    "n_out = len(Y[0])  # 10\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, n_in])\n",
    "t = tf.placeholder(tf.float32, shape=[None, n_out])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "# 入力層 - 隠れ層\n",
    "W0 = tf.Variable(tf.truncated_normal([n_in, n_hidden], stddev=0.01))\n",
    "b0 = tf.Variable(tf.zeros([n_hidden]))\n",
    "h0 = tf.nn.relu(tf.matmul(x, W0) + b0)\n",
    "h0_drop = tf.nn.dropout(h0, keep_prob)\n",
    "\n",
    "# 隠れ層 - 隠れ層\n",
    "W1 = tf.Variable(tf.truncated_normal([n_hidden, n_hidden], stddev=0.01))\n",
    "b1 = tf.Variable(tf.zeros([n_hidden]))\n",
    "h1 = tf.nn.relu(tf.matmul(h0_drop, W1) + b1)\n",
    "h1_drop = tf.nn.dropout(h1, keep_prob)\n",
    "\n",
    "# 隠れ層 - 隠れ層\n",
    "W2 = tf.Variable(tf.truncated_normal([n_hidden, n_hidden], stddev=0.01))\n",
    "b2 = tf.Variable(tf.zeros([n_hidden]))\n",
    "h2 = tf.nn.relu(tf.matmul(h1_drop, W1) + b1)\n",
    "h2_drop = tf.nn.dropout(h2, keep_prob)\n",
    "\n",
    "# 入力層 - 隠れ層\n",
    "W3 = tf.Variable(tf.truncated_normal([n_hidden, n_out], stddev=0.01))\n",
    "b3 = tf.Variable(tf.zeros([n_out]))\n",
    "y = tf.nn.softmax(tf.matmul(h2_drop, W3) + b3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_entropy = -tf.reduce_sum(t * tf.log(y) + (1 - t) * tf.log(1 - y))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.1).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.to_float(tf.greater(y, 0.5)), t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n_batches' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-3826ea7028e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mX_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'n_batches' is not defined"
     ]
    }
   ],
   "source": [
    "epochs = 500\n",
    "batch_size = 100\n",
    "n_bath = N // batch_size\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    X_, Y_ = shuffle(X_train, Y_train)\n",
    "    \n",
    "    for i in range(n_batches):\n",
    "        start = i * batch_size\n",
    "        end = start + batch_size\n",
    "        \n",
    "        sess.run(train_step, feed_dict={\n",
    "            x: X_[start:end],\n",
    "            t: Y_[start:end],\n",
    "            keep_prob: 0.5\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classified = correct_prediction.eval(session=sess, feed_dict={\n",
    "    x: X_test,\n",
    "    t: Y_test\n",
    "})\n",
    "prob = y.eval(session=sess, feed_dict={\n",
    "    x: X_test\n",
    "})\n",
    "print('classified: \\n', classified)\n",
    "print()\n",
    "print('output prob: \\n', prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
